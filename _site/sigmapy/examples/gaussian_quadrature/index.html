<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Gaussian Quadrature &middot; J. Z. Downs
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  tex2jax: {
  inlineMath: [['$','$'], ['\\(','\\)']],
  processEscapes: true},
  TeX: {
  extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"],
  equationNumbers: {
  autoNumber: "AMS"
  }
  }
  });
  </script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML" type="text/javascript"></script>
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>A place for code projects, math, and visualizations.</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/about/">About</a>
        
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/sigmapy/">Sigmapy</a>
        
      
    
      
        
          <a class="sidebar-nav-item active" href="/sigmapy/examples/gaussian_quadrature/">Gaussian Quadrature</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/sigmapy/examples/gaussian_transformation/">Nonlinear Transformation of a Gaussian</a>
        
      
    

    <a class="sidebar-nav-item" href="/archive/v1.0.0.zip">Download</a>
    <a class="sidebar-nav-item" href="">GitHub project</a>
    <span class="sidebar-nav-item">Currently v1.0.0</span>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2019. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">J. Z. Downs</a>
            <small>Computational Mathematician</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="page">
  <h1 class="page-title">Gaussian Quadrature</h1>
  <p>Here we consider the problem of efficiently estimating expected value integrals for a nonlinear function $f(\pmb{x}) : \mathbb{R}^n \to \mathbb{R}^m$
\begin{equation}
E[f(\pmb{x})] = \int_{\mathbb{R}^n} f(\pmb{x}) N(\pmb{x} | \pmb{0}, I) d \pmb{x}.
\end{equation}
Here the notation $N(\pmb{x} | \pmb{0}, I)$ is shorthand for the Gaussian probability density function with mean $\pmb{0}$ and identity covariance matrix, evaluated at the point $\pmb{x}$. In Bayesian filtering applications, the Gaussian weighting function is also referred to as the prior distribution. General Gaussian weight functions $N(\pmb{x} | \pmb{x_0}, P_x)$ are handled by performing a change of variables
\begin{equation}
\int_{\mathbb{R}^n} f(\pmb{x}) N(\pmb{x} | \pmb{x_0}, P_x) d \pmb{x} = \int f(\pmb{x_0} + \sqrt{P_x} \chi) N(\pmb{\chi} | \pmb{0}, I) d \pmb{x}
\end{equation}
where $\sqrt{P_x}$ is a matrix square root (typically obtained by Cholesky factorization) of the covariance matrix $P_x$. We will look at quadrature rules of the form 
\begin{equation}
 E[f(\pmb{x})] \approx Q[f(\pmb{x})] = \sum_i w_i f(\pmb{\chi_i})
\end{equation}
with quadrature points $\pmb{\chi_i}$, also called sigma points, and associated weights $w_i$.</p>

<h2 id="classifying-accuracy">Classifying Accuracy</h2>

<p>The order of accuracy of a Gaussian quadrature rule is usually classified in terms of the degrees of polynomial functions that it can integrate exactly. For multivariate functions we need a few definitions. A monomial of degree $d$ refers to a function 
\begin{equation}
x_1^{N_1} x_2^{N_2} \cdots x_n^{N_n}
\end{equation}
where the $N_i$ are non-negative integers that sum to $d$. A multivariate polynomial of degree $d$ is simply a weighted sum of monomial functions with highest degree $d$. A Gaussian quadrature is said to be $d$-th order if it can exactly integrate expectation integrals for polynomial functions $f(\pmb{x})$ up to and including degree $d$.</p>

<h2 id="gauss-hermite-quadrature">Gauss-Hermite Quadrature</h2>

<p>A standard approach to generate quadrature in many dimensions involves taking tensor products of 1D quadrature rules. In 1D, the third order Gauss-Hermite rule is given by 
\begin{equation}
\int_{\mathbb{R}} f(x) N(x | 0, 1) \; dx \approx \frac{2}{3} f \left ( 0 \right ) + \frac{1}{6} f \left ( -\sqrt{3} \right ) + \frac{1}{6} f \left ( \sqrt{3} \right )
\end{equation}</p>

<p>In $n$ dimensions, sigma points for the third order Gauss-Hermite rule are generated by taking tensor products of the three 1D sigma points. This yields a grid of $3^n$ points. Below we show an example in 3 dimensions. The size of each point corresponds to its weight.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sigmapy.sigma_sets</span> <span class="kn">import</span> <span class="n">SigmaSets</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s">'font.size'</span><span class="p">:</span> <span class="mi">18</span><span class="p">})</span>

<span class="c1"># Prior mean
</span><span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># Prior covariance
</span><span class="n">Px</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># Gauss-Hermite sigma points
</span><span class="n">sets</span> <span class="o">=</span> <span class="n">SigmaSets</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">wm</span><span class="p">,</span> <span class="n">wc</span> <span class="o">=</span> <span class="n">sets</span><span class="o">.</span><span class="n">get_set</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">Px</span><span class="p">,</span> <span class="n">set_name</span> <span class="o">=</span> <span class="s">'hermite'</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s">'3d'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Gauss-Hermite Sigma Points'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,:],</span> <span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">,:],</span> <span class="n">s</span> <span class="o">=</span> <span class="mf">250.</span><span class="o">*</span><span class="n">wm</span> <span class="o">/</span> <span class="n">wm</span><span class="o">.</span><span class="nb">max</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/gaussian_quadrature_files/gaussian_quadrature_1_0.png" alt="png" /></p>

<p>There is a clear drawback of the Gauss-Hermite quadrature rule. The number of sigma points grows exponentially with the state dimension! Hence, while the Gauss-Hermite rule is a useful for low dimensional problems, it is intractable for larger problems.</p>

<h2 id="the-unscented-transform-as-a-quadrature-rule">The Unscented Transform as a Quadrature Rule</h2>
<p>The unscented transform, introduced in <a class="citation" href="#Julier1997">(Julier &amp; Uhlmann, 1997)</a>, is a highly efficient quadrature rule of degree $d=3$. There are several formulations of the unscented transform, but we’ll look at a common version that uses set of $2n + 1$ sigma points. Here, the notation $\pmb{e_i}$ refers to the $i$-th column of the $n \times n$ identity matrix. Points are given by
\begin{equation}
\pmb{\chi_i} =
\begin{cases} 
      \pmb{x_0} &amp; i = 0 \\
      \pmb{x_0} - \sqrt{n + \kappa} \pmb{e_i} &amp; i = 1, \cdots, n\\
      \pmb{x_0} + \sqrt{n + \kappa} \pmb{e_i} &amp; i = n+1, \cdots, 2n
\end{cases}
\end{equation}
with weights
\begin{equation}
w_i^m = w_i^c =
\begin{cases} 
      \frac{\kappa}{n + \kappa} &amp; i = 0 \\
      \frac{1}{2(n+\kappa)} &amp; i = 1, \cdots, 2n.
\end{cases}
\end{equation}
Let’s look at a particular example. Suppose that 
\begin{equation}
f([x_0, x_1, x_2]) = [x_1 x_2 + 1, : x_2^2, : 5 x_0 x_1 x_2 + 2 x_1]
\end{equation}
Below we compute the expected value $ E[f(\pmb{x})]$ using both random sampling and the unscented transform using the Julier sigma points.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>

<span class="c1"># Nonlinear function
</span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">,:]</span> <span class="o">+</span> <span class="mf">1.</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">,:]</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mf">5.</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">,:]</span> <span class="o">+</span> <span class="mf">2.</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]])</span>

<span class="c1"># Estimate expected value via random sampling
</span><span class="n">samples</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="mi">5900</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">y_mean1</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Estimate using Gauss-Hermite
</span><span class="n">X</span><span class="p">,</span> <span class="n">wm</span><span class="p">,</span> <span class="n">wc</span> <span class="o">=</span> <span class="n">sets</span><span class="o">.</span><span class="n">get_set</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">Px</span><span class="p">,</span> <span class="n">set_name</span> <span class="o">=</span> <span class="s">'hermite'</span><span class="p">)</span>
<span class="n">y_mean2</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">wm</span>

<span class="c1"># Estimate using UT
</span><span class="n">X</span><span class="p">,</span> <span class="n">wm</span><span class="p">,</span> <span class="n">wc</span> <span class="o">=</span> <span class="n">sets</span><span class="o">.</span><span class="n">get_set</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">Px</span><span class="p">,</span> <span class="n">set_name</span> <span class="o">=</span> <span class="s">'julier'</span><span class="p">,</span> <span class="n">kappa</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">)</span>
<span class="n">y_mean3</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">wm</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Expected value from random sampling: {}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">y_mean1</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Expected value from Gauss-Hermite: {}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">y_mean2</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Expected value from UT: {}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">y_mean3</span><span class="p">))</span>


<span class="c1"># Plot UT sigmas 
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s">'3d'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'UT Sigma Points'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,:],</span> <span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">,:],</span> <span class="n">s</span> <span class="o">=</span> <span class="mf">250.</span><span class="o">*</span><span class="n">wm</span> <span class="o">/</span> <span class="n">wm</span><span class="o">.</span><span class="nb">max</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Expected value from random sampling: [ 1.01513978  0.9864849  -0.00937191]
Expected value from Gauss-Hermite: [1. 1. 0.]
Expected value from UT: [1. 1. 0.]
</code></pre></div></div>

<p><img src="/assets/images/gaussian_quadrature_files/gaussian_quadrature_3_1.png" alt="png" /></p>

<p>In this case, both the Gauss-Hermite method and the UT exactly (to machine precision) compute the expected value integral since the $f(\pmb{x})$ has terms involving polynomials of at most degree 3. However, the UT only needs 7 sigma points versus 27 for Gauss-Hermite. Nice!</p>

<h2 id="higher-order-terms-and-integration-error">Higher Order Terms and Integration Error</h2>

<p>What about higher order polynomials or non-polynomial functions? A drawback of using a fixed number of sigma points versus taking random samples via MCMC methods is that the order of accuracy is necessarily fixed. For some nonlinear functions, the unscented approximation will be highly accurate (or even perfect), but for others, higher order polynomial terms in the Taylor series expansion for $f$ will result in integration errors. In contrast, MCMC methods can compute expectation integrals to arbitrary precision given enough samples.</p>

<p>Generally, the unscented transform provides more accurate estimates than MCMC methods relative to the number of sigma points / samples respectively. Different quadrature rules and different selections of the scaling parameters for those rules will affect their performance for a given problem. Sigmapy includes algorithms for a variety <a href="/sigmapy/examples/sigma">sets</a> with different numbers of sigma points and levels of accuracy.</p>

<h2 id="bibliography">Bibliography</h2>

<ol class="bibliography"><li><span id="Julier1997">Julier, S. J., &amp; Uhlmann, J. K. (1997). New extension of the Kalman filter to nonlinear systems. <i>Int Symp AerospaceDefense Sensing Simul and Controls</i>. https://doi.org/10.1117/12.280797</span></li></ol>

</div>

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
